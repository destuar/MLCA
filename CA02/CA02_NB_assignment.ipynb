{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iCZYXwtCsL_y"
   },
   "source": [
    "CA02: This is a eMail Spam Classifers that uses Naive Bayes supervised machine learning algorithm. \n",
    "\n",
    "In this assignment you will ...\n",
    "1. Complete the code such a way that it works correctly with this given parts of the program.\n",
    "2. Explain as clearly as possible what each part of the code is doing. Use \"Markdown\" texts and code commenting to explain the code\n",
    "\n",
    "IMPORTANT NOTE:\n",
    "\n",
    "The path of your data folders 'train-mails' and 'test-mails' must be './train-mails' and './test-mails'. This means you must have your .ipynb file and these folders in the SAME FOLDER in your laptop or Google Drive. The reason for doing this is, this way the peer reviewes and I would be able to run your code from our computers using this exact same relative path, irrespective of our folder hierarchy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "4p_DvtT7sOIr",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# Import all other necessary libraries\n",
    "from sklearn.naive_bayes import GaussianNB # Import Gaussian Naive Bayes from sklearn library to build the model\n",
    "from sklearn.metrics import accuracy_score # Import Accuracy Score from sklearn library to calculate the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "jjKF0nIMwz8_",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Function to create a dictionary of words with its frequency from a given directory of emails \n",
    "def make_Dictionary(root_dir): \n",
    "  all_words = [] # List to store all the words in the emails\n",
    "  emails = [os.path.join(root_dir,f) for f in os.listdir(root_dir)] # List to store the path of all the emails\n",
    "  \n",
    "  # Loop to read all the emails in the directory \n",
    "  for mail in emails: \n",
    "    with open(mail) as m: # Open the email\n",
    "      for line in m: # Loop to read all the lines in the email\n",
    "        words = line.split() # Split the line into words\n",
    "        all_words += words # Add the words to the list\n",
    "  \n",
    "  # Create a dictionary of words with the frequency of each word\n",
    "  dictionary = Counter(all_words) \n",
    "  \n",
    "  # Create a list of all the words in the dictionary\n",
    "  list_to_remove = list(dictionary) \n",
    "\n",
    "# Parse the list of words to remove the non-words and single letter words from the dictionary\n",
    "  for item in list_to_remove: # Loop to remove all the words which are not alphabets\n",
    "    if item.isalpha() == False: # Check if the word is not an alphabet\n",
    "      del dictionary[item] # Delete the word from the dictionary\n",
    "    elif len(item) == 1: # Check if the word has only one letter\n",
    "      del dictionary[item] # Delete the word from the dictionary\n",
    "  \n",
    "  # Create a dictionary of 3000 most common words in the emails and return their frequency\n",
    "  dictionary = dictionary.most_common(3000) \n",
    "  return dictionary \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "dmVW5xNlyOFc",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Function to extract features from the emails and create a matrix of features and labels\n",
    "def extract_features(mail_dir):\n",
    "  files = [os.path.join(mail_dir,fi) for fi in os.listdir(mail_dir)] # List to store the path of all the emails\n",
    "  features_matrix = np.zeros((len(files),3000)) # Create a matrix of features with 3000 columns and number of rows equal to the number of emails\n",
    "  train_labels = np.zeros(len(files)) # Create a matrix of labels with the number of rows equal to the number of emails \n",
    "  count = 1; # Variable to store the number of emails\n",
    "  docID = 0; # Variable to store the ID of the email\n",
    "  \n",
    "  # Loop to read all the emails\n",
    "  for fil in files: \n",
    "    with open(fil) as fi: # Open the email \n",
    "      for i, line in enumerate(fi): # Loop to read all the lines in the email \n",
    "        \n",
    "        # Check if the line is the third line of the email \n",
    "        if i ==2: \n",
    "          words = line.split() # Split the line into words\n",
    "          for word in words: # Loop to read all the words in the line \n",
    "            wordID = 0 # Variable to store the ID of the word\n",
    "            \n",
    "            # Loop to read all the words in the dictionary (will be defined from TRAIN_DIR)\n",
    "            for i, d in enumerate(dictionary): \n",
    "              if d[0] == word: # Check if the word is in the dictionary\n",
    "                wordID = i # Store the ID of the word\n",
    "                features_matrix[docID,wordID] = words.count(word) # Store the frequency of the word in the matrix\n",
    "      \n",
    "      # Store the label of the email in the matrix of labels \n",
    "      train_labels[docID] = 0; \n",
    "      filepathTokens = fil.split('/') # Split the path of the email\n",
    "      lastToken = filepathTokens[len(filepathTokens)-1] # Store the last token of the path\n",
    "      \n",
    "      # Check if the email is spam \n",
    "      if lastToken.startswith(\"spmsg\"): \n",
    "        train_labels[docID] = 1; # Store the label of the email\n",
    "        count = count + 1 # Increment the count of spam emails\n",
    "      docID = docID + 1 # Increment the ID of the email\n",
    "  return features_matrix, train_labels # Return the matrix of features and labels            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "zoq-rE7Mx0pp",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Enter the \"path\" of your \"train_mails\" and \"test-mails\" FOLDERS in this cell ...\n",
    "TRAIN_DIR = '/Users/diegoestuar/Desktop/LMU Masters/Semester II/Intro to Machine Learning/Peer Review/CA02/Data/train-mails'\n",
    "TEST_DIR = '/Users/diegoestuar/Desktop/LMU Masters/Semester II/Intro to Machine Learning/Peer Review/CA02/Data/test-mails'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 127480,
     "status": "ok",
     "timestamp": 1578886833446,
     "user": {
      "displayName": "Arin Brahma",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBXGIW7FvUnbm_QmEFGh4rLebuLHNZgc8PuNinU=s64",
      "userId": "05299564422021375910"
     },
     "user_tz": 480
    },
    "id": "134lmhauyQxE",
    "outputId": "83cce6a6-aff5-4e93-ef0a-700606437aa9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading and processing emails from TRAIN and TEST folders\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary of words with its frequency from the training emails\n",
    "dictionary = make_Dictionary(TRAIN_DIR)\n",
    "\n",
    "print (\"reading and processing emails from TRAIN and TEST folders\")\n",
    "features_matrix, labels = extract_features(TRAIN_DIR)\n",
    "test_features_matrix, test_labels = extract_features(TEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 127480,
     "status": "ok",
     "timestamp": 1578886833446,
     "user": {
      "displayName": "Arin Brahma",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBXGIW7FvUnbm_QmEFGh4rLebuLHNZgc8PuNinU=s64",
      "userId": "05299564422021375910"
     },
     "user_tz": 480
    },
    "id": "134lmhauyQxE",
    "outputId": "83cce6a6-aff5-4e93-ef0a-700606437aa9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model. This may take some time ...\n",
      "Classification Completed. Accuracy Score = 0.9653846153846154\n"
     ]
    }
   ],
   "source": [
    "# In this section enter your code to TRAIN the model using Naive Bayes algorithm, then PREDICT and then evaluate PERFORMANCE (Accuracy)\n",
    "# Initialize the Gaussian Naive Bayes model\n",
    "model = GaussianNB()\n",
    "\n",
    "print(\"Training Model. This may take some time ...\")\n",
    "\n",
    "# Train the model using the training dataset\n",
    "model.fit(features_matrix, labels)\n",
    "\n",
    "# Predict the labels of the test dataset\n",
    "predicted_labels = model.predict(test_features_matrix)\n",
    "\n",
    "# Print the accuracy of the model on the test dataset\n",
    "print(f'Classification Completed. Accuracy Score =',accuracy_score(test_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M5_mPrvN586A"
   },
   "source": [
    "======================= END OF PROGRAM ========================="
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOaSi3qlFUlqTup/1esXCKD",
   "collapsed_sections": [],
   "name": "naive_bayes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
